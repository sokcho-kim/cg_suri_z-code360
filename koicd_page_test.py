import asyncio
import json
from playwright.async_api import async_playwright

async def analyze_koicd_page():
    """
    KOICD íŽ˜ì´ì§€ ì¢…í•© ë¶„ì„:
    1. ëª¨ë“  í…Œì´ë¸” ë¶„ì„ (id, class, ë‚´ìš©)
    2. loading vs ì‹¤ì œ ë°ì´í„° í…Œì´ë¸” êµ¬ë¶„
    3. ë™ì  ë¡œë”© í™•ì¸ ë° ìµœì  ëŒ€ê¸° ë°©ë²•
    4. ìˆ˜ê°€ì½”ë“œ ë°ì´í„° í…Œì´ë¸” ì •í™•í•œ ì…€ë ‰í„°
    5. ë°ì´í„° í–‰ êµ¬ì¡° ë° í´ë¦­ ê°€ëŠ¥í•œ td ë¶„ì„
    6. ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ëª¨ë‹ˆí„°ë§
    7. ìŠ¤í¬ë¦°ìƒ· ì €ìž¥
    """
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()
        
        # ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ëª¨ë‹ˆí„°ë§ ì„¤ì •
        network_requests = []
        
        def handle_request(request):
            network_requests.append({
                'url': request.url,
                'method': request.method,
                'headers': dict(request.headers),
                'post_data': request.post_data
            })
        
        def handle_response(response):
            for req in network_requests:
                if req['url'] == response.url:
                    req['status'] = response.status
                    req['response_headers'] = dict(response.headers)
                    break
        
        page.on('request', handle_request)
        page.on('response', handle_response)
        
        try:
            print("ðŸ” KOICD íŽ˜ì´ì§€ ì¢…í•© ë¶„ì„ ì‹œìž‘...")
            
            # ë„¤íŠ¸ì›Œí¬ íƒ€ìž„ì•„ì›ƒ ì„¤ì •
            page.set_default_timeout(30000)
            
            # íŽ˜ì´ì§€ ì ‘ê·¼
            print("ðŸ“¡ íŽ˜ì´ì§€ ë¡œë”© ì¤‘...")
            await page.goto("https://www.koicd.kr/ins/act.do")
            
            # 1ë‹¨ê³„: ì´ˆê¸° ë¡œë”© ì™„ë£Œ ëŒ€ê¸°
            await page.wait_for_load_state('domcontentloaded')
            print("âœ… DOM ë¡œë”© ì™„ë£Œ")
            
            # ì´ˆê¸° ìƒíƒœ ìŠ¤í¬ë¦°ìƒ·
            await page.screenshot(path="koicd_initial_state.png", full_page=True)
            print("ðŸ“¸ ì´ˆê¸° ìƒíƒœ ìŠ¤í¬ë¦°ìƒ· ì €ìž¥")
            
            # 2ë‹¨ê³„: ì´ˆê¸° í…Œì´ë¸” ë¶„ì„
            print("\nðŸ“Š ì´ˆê¸° í…Œì´ë¸” ìƒíƒœ ë¶„ì„...")
            initial_tables = await analyze_all_tables(page, "ì´ˆê¸°")
            
            # 3ë‹¨ê³„: ë„¤íŠ¸ì›Œí¬ idle ëŒ€ê¸°
            await page.wait_for_load_state('networkidle')
            print("âœ… ë„¤íŠ¸ì›Œí¬ idle ì™„ë£Œ")
            
            # 4ë‹¨ê³„: ì¶”ê°€ ëŒ€ê¸° í›„ ìž¬ë¶„ì„
            await page.wait_for_timeout(5000)
            print("\nðŸ“Š ë„¤íŠ¸ì›Œí¬ idle í›„ í…Œì´ë¸” ìƒíƒœ ìž¬ë¶„ì„...")
            final_tables = await analyze_all_tables(page, "ìµœì¢…")
            
            # ìµœì¢… ìƒíƒœ ìŠ¤í¬ë¦°ìƒ·
            await page.screenshot(path="koicd_final_state.png", full_page=True)
            print("ðŸ“¸ ìµœì¢… ìƒíƒœ ìŠ¤í¬ë¦°ìƒ· ì €ìž¥")
            
            # 5ë‹¨ê³„: ë°ì´í„° í…Œì´ë¸” ì •í™•í•œ ì…€ë ‰í„° ì°¾ê¸°
            print("\nðŸŽ¯ ìˆ˜ê°€ì½”ë“œ ë°ì´í„° í…Œì´ë¸” ì •í™•í•œ ì…€ë ‰í„° ë¶„ì„...")
            data_table_info = await find_data_table_selector(page)
            
            # 6ë‹¨ê³„: ë°ì´í„° í–‰ êµ¬ì¡° ë° í´ë¦­ ë¶„ì„
            print("\nðŸ“‹ ë°ì´í„° í–‰ êµ¬ì¡° ë° í´ë¦­ ê°€ëŠ¥ ìš”ì†Œ ë¶„ì„...")
            row_structure_info = await analyze_row_structure(page)
            
            # 7ë‹¨ê³„: ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¶„ì„
            print("\nðŸŒ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¶„ì„...")
            analyze_network_requests(network_requests)
            
            # 8ë‹¨ê³„: ìµœì  ë¡œë”© ì „ëžµ ì œì•ˆ
            print("\nðŸ’¡ ìµœì  ë¡œë”© ëŒ€ê¸° ì „ëžµ ì œì•ˆ...")
            suggest_optimal_loading_strategy(initial_tables, final_tables, network_requests)
            
            # ë¶„ì„ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ìž¥
            analysis_result = {
                'initial_tables': initial_tables,
                'final_tables': final_tables,
                'data_table_info': data_table_info,
                'row_structure_info': row_structure_info,
                'network_requests': network_requests[:10]  # ì²˜ìŒ 10ê°œë§Œ ì €ìž¥
            }
            
            with open('koicd_analysis_result.json', 'w', encoding='utf-8') as f:
                json.dump(analysis_result, f, ensure_ascii=False, indent=2)
            print("ðŸ’¾ ë¶„ì„ ê²°ê³¼ JSON ì €ìž¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            try:
                await page.screenshot(path="koicd_error_screenshot.png")
                print("ðŸ“¸ ì˜¤ë¥˜ ìŠ¤í¬ë¦°ìƒ· ì €ìž¥")
            except:
                pass
        
        finally:
            await browser.close()

async def analyze_all_tables(page, stage):
    """íŽ˜ì´ì§€ì˜ ëª¨ë“  í…Œì´ë¸” ë¶„ì„"""
    print(f"   ðŸ“‹ {stage} ë‹¨ê³„ - í…Œì´ë¸” ë¶„ì„:")
    
    tables_info = []
    try:
        tables = await page.query_selector_all("table")
        print(f"      ì´ {len(tables)}ê°œ í…Œì´ë¸” ë°œê²¬")
        
        for i, table in enumerate(tables):
            info = {
                'index': i + 1,
                'id': await table.get_attribute('id') or '',
                'class': await table.get_attribute('class') or '',
                'style': await table.get_attribute('style') or '',
                'visible': await table.is_visible()
            }
            
            # ìœ„ì¹˜ ì •ë³´
            bbox = await table.bounding_box()
            info['position'] = bbox if bbox else 'hidden'
            
            # êµ¬ì¡° ì •ë³´
            if info['visible']:
                rows = await table.query_selector_all('tr')
                tbody_rows = await table.query_selector_all('tbody tr')
                headers = await table.query_selector_all('th')
                
                info['structure'] = {
                    'total_rows': len(rows),
                    'tbody_rows': len(tbody_rows),
                    'headers': len(headers)
                }
                
                # ë‚´ìš© ìƒ˜í”Œ
                if tbody_rows:
                    first_row = await tbody_rows[0].text_content()
                    info['sample_content'] = first_row.strip()[:100]
                elif rows:
                    first_row = await rows[0].text_content()
                    info['sample_content'] = first_row.strip()[:100]
                else:
                    info['sample_content'] = 'ë‚´ìš© ì—†ìŒ'
            else:
                info['structure'] = 'ìˆ¨ê²¨ì§„ í…Œì´ë¸”'
                info['sample_content'] = 'ìˆ¨ê²¨ì§„ í…Œì´ë¸”'
            
            # ë¶€ëª¨ ì»¨í…Œì´ë„ˆ ì •ë³´
            parent = await table.query_selector('xpath=..')
            if parent:
                parent_tag = await parent.evaluate('el => el.tagName')
                parent_id = await parent.get_attribute('id') or ''
                parent_class = await parent.get_attribute('class') or ''
                info['parent'] = f"{parent_tag.lower()}" + (f"#{parent_id}" if parent_id else "") + (f".{parent_class.split()[0]}" if parent_class else "")
            
            tables_info.append(info)
            
            print(f"      í…Œì´ë¸” #{i+1}: id='{info['id']}', class='{info['class']}', visible={info['visible']}")
            if info['visible']:
                print(f"                 êµ¬ì¡°: {info['structure']}, ë¶€ëª¨: {info.get('parent', 'N/A')}")
                print(f"                 ë‚´ìš©: {info['sample_content']}")
    
    except Exception as e:
        print(f"      âŒ í…Œì´ë¸” ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    return tables_info

async def find_data_table_selector(page):
    """ìˆ˜ê°€ì½”ë“œ ë°ì´í„°ê°€ ìžˆëŠ” í…Œì´ë¸”ì˜ ì •í™•í•œ ì…€ë ‰í„° ì°¾ê¸°"""
    data_table_info = {}
    
    try:
        # ë‹¤ì–‘í•œ ì…€ë ‰í„°ë¡œ ë°ì´í„° í…Œì´ë¸” ì°¾ê¸°
        selectors_to_try = [
            "#container table",
            "table[class*='data']",
            "table[id*='data']",
            ".table-container table",
            "#content table",
            "table tbody tr[class]"
        ]
        
        for selector in selectors_to_try:
            try:
                elements = await page.query_selector_all(selector)
                if elements:
                    print(f"      ì…€ë ‰í„° '{selector}': {len(elements)}ê°œ ìš”ì†Œ ë°œê²¬")
                    
                    # ì²« ë²ˆì§¸ ìš”ì†Œì˜ ë‚´ìš© í™•ì¸
                    if len(elements) > 0:
                        content = await elements[0].text_content()
                        if 'ìˆ˜ê°€' in content or 'suga' in content.lower() or len(content) > 50:
                            data_table_info['best_selector'] = selector
                            data_table_info['element_count'] = len(elements)
                            data_table_info['sample_content'] = content[:200]
                            print(f"      âœ… ë°ì´í„° í…Œì´ë¸” í›„ë³´: {selector}")
            
            except Exception:
                continue
        
        # #container table tbody tr ë¶„ì„ (ê¸°ì¡´ ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ë˜ ì…€ë ‰í„°)
        container_rows = await page.query_selector_all("#container table tbody tr")
        if container_rows:
            data_table_info['container_rows_count'] = len(container_rows)
            print(f"      #container table tbody tr: {len(container_rows)}ê°œ í–‰")
            
            # ì²« ë²ˆì§¸ í–‰ ë¶„ì„
            if len(container_rows) > 0:
                first_row = container_rows[0]
                row_class = await first_row.get_attribute('class')
                row_content = await first_row.text_content()
                
                data_table_info['first_row'] = {
                    'class': row_class,
                    'content': row_content.strip()[:100]
                }
                print(f"      ì²« ë²ˆì§¸ í–‰ class: '{row_class}', ë‚´ìš©: '{row_content.strip()[:50]}...'")
    
    except Exception as e:
        print(f"      âŒ ë°ì´í„° í…Œì´ë¸” ì…€ë ‰í„° ì°¾ê¸° ì˜¤ë¥˜: {e}")
    
    return data_table_info

async def analyze_row_structure(page):
    """ë°ì´í„° í–‰ì˜ êµ¬ì¡°ì™€ í´ë¦­ ê°€ëŠ¥í•œ td ë¶„ì„"""
    row_info = {}
    
    try:
        rows = await page.query_selector_all("#container table tbody tr")
        if rows:
            print(f"      ë¶„ì„í•  í–‰ ê°œìˆ˜: {len(rows)}")
            
            # ì²« ë²ˆì§¸ ë°ì´í„° í–‰ ë¶„ì„
            first_row = rows[0] if rows else None
            if first_row:
                tds = await first_row.query_selector_all("td")
                row_info['td_count'] = len(tds)
                row_info['td_contents'] = []
                row_info['clickable_tds'] = []
                
                print(f"      ì²« ë²ˆì§¸ í–‰ì˜ td ê°œìˆ˜: {len(tds)}")
                
                for i, td in enumerate(tds):
                    content = await td.text_content()
                    row_info['td_contents'].append({
                        'index': i,
                        'content': content.strip()[:50],
                        'full_content': content.strip()
                    })
                    
                    # í´ë¦­ ê°€ëŠ¥ì„± í™•ì¸
                    cursor_style = await td.evaluate('el => window.getComputedStyle(el).cursor')
                    onclick = await td.get_attribute('onclick')
                    has_link = await td.query_selector('a')
                    
                    if cursor_style == 'pointer' or onclick or has_link:
                        row_info['clickable_tds'].append({
                            'index': i,
                            'reason': 'cursor:pointer' if cursor_style == 'pointer' else 'onclick' if onclick else 'has_link'
                        })
                    
                    print(f"        TD[{i}]: '{content.strip()[:30]}...', í´ë¦­ê°€ëŠ¥: {cursor_style == 'pointer' or bool(onclick) or bool(has_link)}")
                
                # í–‰ í´ëž˜ìŠ¤ íŒ¨í„´ ë¶„ì„
                row_classes = []
                for row in rows[:5]:  # ì²˜ìŒ 5ê°œ í–‰ë§Œ ë¶„ì„
                    row_class = await row.get_attribute('class')
                    if row_class:
                        row_classes.append(row_class)
                
                row_info['row_class_patterns'] = list(set(row_classes))
                print(f"      í–‰ í´ëž˜ìŠ¤ íŒ¨í„´: {row_info['row_class_patterns']}")
    
    except Exception as e:
        print(f"      âŒ í–‰ êµ¬ì¡° ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    return row_info

def analyze_network_requests(requests):
    """ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¶„ì„"""
    print(f"      ì´ {len(requests)}ê°œ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë°œìƒ")
    
    ajax_requests = []
    for req in requests:
        if req['method'] in ['POST', 'PUT'] or 'json' in req.get('response_headers', {}).get('content-type', '').lower():
            ajax_requests.append(req)
    
    print(f"      AJAX/API ìš”ì²­: {len(ajax_requests)}ê°œ")
    
    for i, req in enumerate(ajax_requests[:5]):  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
        print(f"        {i+1}. {req['method']} {req['url']}")
        if req.get('post_data'):
            print(f"           POST ë°ì´í„°: {req['post_data'][:100]}...")

def suggest_optimal_loading_strategy(initial_tables, final_tables, network_requests):
    """ìµœì  ë¡œë”© ì „ëžµ ì œì•ˆ"""
    print("      ê¶Œìž¥ ë¡œë”© ì „ëžµ:")
    print("      1. page.goto(url)")
    print("      2. wait_for_load_state('domcontentloaded')")
    print("      3. wait_for_load_state('networkidle')")
    
    if len(final_tables) > len(initial_tables):
        print("      4. âœ… ë™ì  í…Œì´ë¸” ë¡œë”© í™•ì¸ë¨ - ì¶”ê°€ ëŒ€ê¸° í•„ìš”")
    
    ajax_count = len([r for r in network_requests if r['method'] in ['POST', 'PUT']])
    if ajax_count > 0:
        print(f"      5. âš ï¸ {ajax_count}ê°œ AJAX ìš”ì²­ í™•ì¸ - ë°ì´í„° ë¡œë”© ì™„ë£Œê¹Œì§€ ì¶”ê°€ ëŒ€ê¸°")
        print("         - #container table tbody tr ìš”ì†Œ í™•ì¸")
        print("         - ì²« ë²ˆì§¸ í–‰ì— ì‹¤ì œ ë°ì´í„° ìžˆëŠ”ì§€ í™•ì¸")
    
    print("\n      ðŸ’» êµ¬í˜„ ì˜ˆì‹œ:")
    print("""
    await page.goto(url)
    await page.wait_for_load_state('networkidle')
    
    # ë°ì´í„° í…Œì´ë¸” ë¡œë”© ì™„ë£Œ ëŒ€ê¸°
    await page.wait_for_selector('#container table tbody tr', timeout=15000)
    
    # ì‹¤ì œ ë°ì´í„° í™•ì¸
    for attempt in range(10):
        rows = await page.query_selector_all('#container table tbody tr')
        if rows and len(rows) > 0:
            first_row_text = await rows[0].text_content()
            if first_row_text.strip() and 'ë¡œë”©' not in first_row_text:
                break
        await page.wait_for_timeout(1000)
    """)

if __name__ == "__main__":
    asyncio.run(analyze_koicd_page())