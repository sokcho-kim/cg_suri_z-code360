import os
import time
import json
import csv
import asyncio
from playwright.async_api import async_playwright

# ê²½ë¡œ ì„¤ì •
BASE_URL = "https://www.koicd.kr/ins/act.do"
BASE_DIR = os.path.abspath("suga_results")
JSON_DIR = os.path.join(BASE_DIR, "json_pages")
FAILED_FILE = os.path.join(BASE_DIR, "failed_codes.txt")
CSV_FILE = os.path.join(BASE_DIR, "suga_info_detailed.csv")

# í´ë” ìƒì„±
os.makedirs(JSON_DIR, exist_ok=True)

async def extract_detail_info(page, row_selector):
    """ìƒì„¸ ì •ë³´ íŒì—…ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
    try:
        # 3ë²ˆì§¸ td í´ë¦­
        td_element = await page.query_selector(f"{row_selector} td:nth-child(3)")
        if td_element:
            await td_element.click()
            await page.wait_for_timeout(1000)  # íŒì—… ë¡œë”© ëŒ€ê¸°
            
            # ìƒì„¸ ì •ë³´ divê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            detail_div = await page.wait_for_selector(".div_table_style", timeout=5000)
            
            if detail_div:
                # ìƒì„¸ ì •ë³´ í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¶”ì¶œ
                detail_data = {}
                
                # ê° í–‰ì—ì„œ ë°ì´í„° ì¶”ì¶œ
                rows = await detail_div.query_selector_all("table tbody tr")
                
                for row in rows:
                    ths = await row.query_selector_all("th")
                    tds = await row.query_selector_all("td")
                    
                    if len(ths) == 1 and len(tds) >= 1:  # ë‹¨ì¼ th-td êµ¬ì¡°
                        th_text = (await ths[0].text_content()).strip()
                        
                        if len(tds) == 1:  # colspan=3ì¸ ê²½ìš°
                            td_text = (await tds[0].text_content()).strip()
                            detail_data[th_text] = td_text
                        elif len(tds) == 3:  # ì¼ë°˜ì ì¸ ê²½ìš°
                            td_text = (await tds[0].text_content()).strip()
                            detail_data[th_text] = td_text
                    
                    elif len(ths) == 2 and len(tds) == 2:  # 2ê°œ th-td ìŒ
                        th1_text = (await ths[0].text_content()).strip()
                        td1_text = (await tds[0].text_content()).strip()
                        th2_text = (await ths[1].text_content()).strip()
                        td2_text = (await tds[1].text_content()).strip()
                        
                        detail_data[th1_text] = td1_text
                        detail_data[th2_text] = td2_text
                
                # íŒì—… ë‹«ê¸° ë²„íŠ¼ í´ë¦­
                close_btn = await detail_div.query_selector("button:has-text('ë‹«ê¸°')")
                if close_btn:
                    await close_btn.click()
                    await page.wait_for_timeout(500)
                
                return detail_data
            
    except Exception as e:
        print(f"âŒ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        # íŒì—…ì´ ì—´ë ¤ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ë‹«ê¸° ì‹œë„
        try:
            close_btn = await page.query_selector(".div_table_style button:has-text('ë‹«ê¸°')")
            if close_btn:
                await close_btn.click()
                await page.wait_for_timeout(500)
        except:
            pass
        
        return {}

async def scrape_koicd():
    async with async_playwright() as p:
        # ë¸Œë¼ìš°ì € ì‹œì‘
        browser = await p.chromium.launch(headless=False)  # ë””ë²„ê¹…ìš©ìœ¼ë¡œ headless=False
        page = await browser.new_page()
        
        # ë·°í¬íŠ¸ í¬ê¸° ì„¤ì • (íŒì—…ì´ ì˜ ë³´ì´ë„ë¡)
        await page.set_viewport_size({"width": 1920, "height": 1080})
        
        # ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        page.set_default_timeout(30000)
        
        all_data = []
        failed_codes = []
        page_num = 1
        
        await page.goto(BASE_URL)
        await page.wait_for_load_state('networkidle')
        
        while True:
            print(f"\nâ–¶ í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì¤‘...")
            
            try:
                # í…Œì´ë¸” ë¡œë”© ëŒ€ê¸°
                await page.wait_for_selector("#container table tbody tr", timeout=10000)
                
                # í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  ë°ì´í„° í–‰ ê°€ì ¸ì˜¤ê¸°
                rows = await page.query_selector_all("#container table tbody tr")
                print(f"ğŸ“‹ í˜„ì¬ í˜ì´ì§€ í–‰ ìˆ˜: {len(rows)}")
                
                page_data = []
                
                for i, row in enumerate(rows):
                    try:
                        # í´ë˜ìŠ¤ê°€ ìˆ«ìì¸ í–‰ë§Œ ì²˜ë¦¬ (ë°ì´í„° í–‰)
                        row_class = await row.get_attribute("class")
                        if not row_class or not any(c.isdigit() for c in row_class):
                            continue
                        
                        print(f"  ğŸ” í–‰ {i+1} ì²˜ë¦¬ ì¤‘... (class: {row_class})")
                        
                        # ğŸ” ë””ë²„ê¹…: TD êµ¬ì¡° í™•ì¸
                        tds = await row.query_selector_all("td")
                        print(f"    ğŸ“Š TD ê°œìˆ˜: {len(tds)}")
                        
                        # ê° TD ë‚´ìš© ì¶œë ¥ (ì²˜ìŒ 5ê°œë§Œ)
                        for j, td in enumerate(tds[:5]):
                            td_text = (await td.text_content()).strip()
                            print(f"    TD[{j}]: '{td_text}'")
                        
                        if len(tds) < 3:
                            print(f"    âš ï¸ TDê°€ 3ê°œ ë¯¸ë§Œì„. ê±´ë„ˆëœ€.")
                            continue
                        
                        # ğŸ” ìˆ˜ê°€ì½”ë“œ ìœ„ì¹˜ í™•ì¸ (ì—¬ëŸ¬ ìœ„ì¹˜ ì‹œë„)
                        suga_code = ""
                        for idx in range(min(3, len(tds))):
                            potential_code = (await tds[idx].text_content()).strip()
                            if potential_code and len(potential_code) > 2:  # ì˜ë¯¸ìˆëŠ” ì½”ë“œì¸ì§€ í™•ì¸
                                suga_code = potential_code
                                print(f"    ğŸ¯ ìˆ˜ê°€ì½”ë“œ ë°œê²¬ TD[{idx}]: '{suga_code}'")
                                break
                        
                        if not suga_code:
                            print(f"    âŒ ìˆ˜ê°€ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                            continue
                        
                        kor_name = (await tds[1].text_content()).strip() if len(tds) > 1 else ""
                        eng_name = (await tds[2].text_content()).strip() if len(tds) > 2 else ""
                        
                        # í–‰ì˜ ê³ ìœ  selector ìƒì„±
                        row_selector = f"#container table tbody tr.\\{row_class.replace(' ', '.')}"
                        
                        # ìƒì„¸ ì •ë³´ ì¶”ì¶œ
                        print(f"    ğŸ“ {suga_code} ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì¤‘...")
                        detail_info = await extract_detail_info(page, row_selector)
                        
                        # ë°ì´í„° í†µí•©
                        combined_data = {
                            "ìˆ˜ê°€ì½”ë“œ": suga_code,
                            "í–‰ìœ„ëª…(í•œê¸€)_ê¸°ë³¸": kor_name,
                            "í–‰ìœ„ëª…(ì˜ë¬¸)_ê¸°ë³¸": eng_name,
                            **detail_info  # ìƒì„¸ ì •ë³´ ì¶”ê°€
                        }
                        
                        page_data.append(combined_data)
                        print(f"    âœ… {suga_code} ì™„ë£Œ")
                        
                        # ìš”ì²­ ê°„ ë”œë ˆì´
                        await page.wait_for_timeout(500)
                        
                    except Exception as e:
                        print(f"    âŒ í–‰ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        if 'suga_code' in locals():
                            failed_codes.append(suga_code)
                        continue
                
                # í˜ì´ì§€ë³„ JSON ì €ì¥
                json_path = os.path.join(JSON_DIR, f"page_{page_num}_detailed.json")
                with open(json_path, "w", encoding="utf-8") as jf:
                    json.dump(page_data, jf, ensure_ascii=False, indent=2)
                
                all_data.extend(page_data)
                print(f"ğŸ“„ í˜ì´ì§€ {page_num} ì™„ë£Œ: {len(page_data)}ê°œ í•­ëª©")
                
                # ì¤‘ê°„ CSV ì €ì¥
                save_to_csv(all_data)
                
                # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
                try:
                    # í˜ì´ì§€ë„¤ì´ì…˜ì—ì„œ ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ ì°¾ê¸°
                    next_page_num = page_num + 1
                    
                    # ë‹¤ìŒ í˜ì´ì§€ ë§í¬ ì°¾ê¸° (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
                    next_selectors = [
                        f"a:has-text('{next_page_num}')",
                        f".pagination a:has-text('{next_page_num}')",
                        f"a[href*='page={next_page_num}']",
                        "a:has-text('ë‹¤ìŒ')",
                        "a:has-text('>')",
                        ".next"
                    ]
                    
                    next_btn = None
                    for selector in next_selectors:
                        try:
                            next_btn = await page.query_selector(selector)
                            if next_btn:
                                print(f"ğŸ”— ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ë°œê²¬: {selector}")
                                break
                        except:
                            continue
                    
                    if next_btn:
                        await next_btn.scroll_into_view_if_needed()
                        await next_btn.click()
                        await page.wait_for_load_state('networkidle')
                        page_num += 1
                        
                        # í˜ì´ì§€ ë³€ê²½ í™•ì¸ì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                        await page.wait_for_timeout(2000)
                    else:
                        print(f"â›” ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ íŒë‹¨.")
                        break
                        
                except Exception as e:
                    print(f"â›” í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: {e}")
                    break
                
            except Exception as e:
                print(f"âŒ í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                break
        
        await browser.close()
        
        # ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥
        with open(FAILED_FILE, "w", encoding="utf-8") as ff:
            for code in failed_codes:
                ff.write(code + "\n")
        
        print(f"\nğŸ“¦ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"âœ… ì´ {len(all_data)}ê°œ í•­ëª© ìˆ˜ì§‘")
        print(f"âŒ ì‹¤íŒ¨í•œ í•­ëª©: {len(failed_codes)}ê°œ")
        
        return all_data, failed_codes

def save_to_csv(data):
    """CSV íŒŒì¼ë¡œ ì €ì¥"""
    if not data:
        return
    
    try:
        # ëª¨ë“  í‚¤ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì»¬ëŸ¼ í—¤ë” ìƒì„±
        all_keys = set()
        for item in data:
            all_keys.update(item.keys())
        
        # ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬ (ê¸°ë³¸ ì •ë³´ë¥¼ ì•ìœ¼ë¡œ)
        priority_cols = ["ìˆ˜ê°€ì½”ë“œ", "í–‰ìœ„ëª…(í•œê¸€)_ê¸°ë³¸", "í–‰ìœ„ëª…(ì˜ë¬¸)_ê¸°ë³¸", "ë¶„ë¥˜ì½”ë“œ", "ë¶„ë¥˜ë‹¨ê³„"]
        ordered_cols = []
        
        for col in priority_cols:
            if col in all_keys:
                ordered_cols.append(col)
                all_keys.remove(col)
        
        ordered_cols.extend(sorted(all_keys))
        
        with open(CSV_FILE, "w", newline="", encoding="utf-8-sig") as cf:
            writer = csv.DictWriter(cf, fieldnames=ordered_cols)
            writer.writeheader()
            
            for item in data:
                # ë¹ˆ ê°’ë“¤ì„ ""ë¡œ ì±„ìš°ê¸°
                row_data = {col: item.get(col, "") for col in ordered_cols}
                writer.writerow(row_data)
        
        print(f"ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: {CSV_FILE} ({len(data)}ê°œ í•­ëª©)")
        
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")

# ì‹¤í–‰
if __name__ == "__main__":
    all_data, failed_codes = asyncio.run(scrape_koicd())
    
    print(f"\nğŸ¯ ìµœì¢… ê²°ê³¼:")
    print(f"   ğŸ“Š ìˆ˜ì§‘ëœ ì´ í•­ëª©: {len(all_data)}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨í•œ í•­ëª©: {len(failed_codes)}ê°œ")
    print(f"   ğŸ“ ì €ì¥ ìœ„ì¹˜: {CSV_FILE}")